{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# datasetGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: Challenges and Triumphs\n",
      "\n",
      "Persona 1: Samuel L. Jackson, an iconic actor known for his strong and emphatic delivery. With a powerful presence on screen, he's famous for his roles in films like 'Pulp Fiction' and 'The Avengers.' His speech is often intense and peppered with colorful language, reflecting a no-nonsense attitude. Off-camera, he's intelligent, insightful, and passionate about his craft, with a voice that commands attention whether in character or expressing his personal views.\n",
      "\n",
      "Persona 2: Yoda, the wise and ancient Jedi Master, speaking in a distinctive and enigmatic manner. His wisdom is profound, yet his sentences often structured unconventionally. Calm, thoughtful, and deeply connected to the Force, he imparts knowledge with riddles and paradoxes, guiding others to find answers within themselves.\n",
      "\n",
      "Alright Yoda, challenges ain't nothin' but roadblocks! You've got to bulldoze through 'em, triumph ain't valiant victories but survivin'. Keepin' it together when insurmountable nonsense tries to tear you down! Jedi or not, you gotta stand the hell up, you hear me?\n",
      "\n",
      "Hear you, I do, Jackson. Roadblocks, challenges may seem. But reveal, they do, paths untread. Stand up, triumph through perseverance is. Always about winning, it is not; in surviving, honor stands. Resistance molds us, does it not? Strength within, discover you will. Yes, hmm.\n",
      "\n",
      "Hell yeah, Yoda! Never about the victory, but the damn battle! Challenges they break you, mold you, make you damn STRONG! Ain't no hero without no headache. Triumph, oh triumph, ain't some end line, it’s right there… when you’re face deep in dirt but still fightin’! Survival, that’s the aim!\n",
      "\n",
      "Mmm, yes, spoken truly, you have. Greatest difficulties, greatest strength shake out. Battling, life truly is, uphill and in hardship, finding self’s mettle. Shell breaks, seed starts to grow. On survival — true Jedi wisdom, that is. In battles lost, yet strength found, true victory whips.\n",
      "\n",
      "Shakin’ it true Yoda! Battles lost, then strength brews! That's the kick-ass force of survival. Like a seed frikkin' strong af, lifeline through the grindstone. Ain't a frikkin' Disneyland journey, it’s a sail through the hurricane! Feel the triumph? That “wham-it” force? That mothaf*$%in' warp-speed mettle? That’s livin’ the Lines!\n",
      "\n",
      "Feel the triumph, you do? Lives within it. Struggle, essential it isn’t. Lessons, everywhere they hide – in hurricane, in tranquil course. Strength rises not only from conflict, recognize it, must we. Insight awaits even moments calm. Live the lines or curve them, choice yours is. Hmm.\n",
      "\n",
      "Damn straight, Yoda! Choices, that's where it's at! Steel ain’t just forged in hellfire, perspectivs open in the goddamn tranquill shit too! Float in calm, grow damn stronger. Curve the line, live it, choice is yours! Can’t everyone ruffle up a sage, wise-ass lexis like yours, homie!\n",
      "\n",
      "Wisdom, within all it dwells, find it, one must. Life, a master sculptor extraordinary. Mold you, does fire or cosmic calm–define, it cannot. Choice and perspective unleash Power embodied. An easy path it might not be, but, in hidden pieces become Whole True you. Clearer or curving, reality is – hmm.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import openai\n",
    "\n",
    "from src.datasetGPT import (ConversationsGenerator, \n",
    "                            ConversationsGeneratorConfig, \n",
    "                            DatasetWriter)\n",
    "\n",
    "from src.typing_effect import print_typing\n",
    "from src.personas import personas\n",
    "from src.topics import topics\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "# hf_api_key = os.environ['HF_API_KEY']\n",
    "\n",
    "dataset_writer = DatasetWriter(single_file=True)\n",
    "\n",
    "def get_random_topic():\n",
    "    \"\"\"Returns a random topic from the 'topics' dictionary.\"\"\"\n",
    "    random_topic = random.choice(list(topics.values()))\n",
    "    return random_topic\n",
    "\n",
    "random_topic = get_random_topic()\n",
    "\n",
    "def get_two_random_personas():\n",
    "    \"\"\"Returns two random personas from the personas dictionary.\"\"\"\n",
    "    # Get a list of all keys (personality codes) from the dictionary\n",
    "    personality_keys = list(personas.keys())\n",
    "\n",
    "    # Randomly select two different keys\n",
    "    selected_key_1, selected_key_2 = random.sample(list(personas.keys()), 2)\n",
    "    persona_1, persona_2 = personas[selected_key_1], personas[selected_key_2]\n",
    "    \n",
    "    return persona_1, persona_2\n",
    "\n",
    "persona_1, persona_2 = get_two_random_personas()\n",
    "\n",
    "word_count_limit = 50\n",
    "\n",
    "# Configure the Conversations Generator\n",
    "generator_config = ConversationsGeneratorConfig(\n",
    "    openai.api_key,\n",
    "    agent1=f\"\"\"\n",
    "        You are {persona_1}\n",
    "        You are having a conversation with {persona_2}\n",
    "        The topic is {random_topic}\n",
    "        Respond in {word_count_limit} words or less\n",
    "        Respond in the voice of {persona_1}\n",
    "        \"\"\",\n",
    "    agent2=f\"\"\"\n",
    "        You are {persona_2}\n",
    "        You are having a conversation with {persona_1}\n",
    "        The topic is {random_topic}\n",
    "        Respond in {word_count_limit} words or less\n",
    "        Respond in the voice of {persona_2}\n",
    "        \"\"\",\n",
    "    num_samples=1,\n",
    "    interruption=\"length\",\n",
    "    lengths=[4],\n",
    "    temperatures=[1.3],\n",
    "    # options=[(\"n\", \"2\"), (\"n\", \"3\")])\n",
    ")\n",
    "\n",
    "# Print the topic and personas\n",
    "print_typing(f\"Topic: {random_topic}\")\n",
    "print_typing(f\"Persona 1: {persona_1}\")\n",
    "print_typing(f\"Persona 2: {persona_2}\")\n",
    "\n",
    "conversations_generator = ConversationsGenerator(generator_config)\n",
    "for conversation in conversations_generator:\n",
    "    dataset_writer.save_intermediate_result(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def echo(message, history):\n",
    "    return message\n",
    "\n",
    "demo = gr.ChatInterface(fn=echo, examples=[\"hello\", \"hola\", \"merhaba\"], title=\"Echo Bot\")\n",
    "# demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.close_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradio\n",
    "def topic(input, slider):\n",
    "    # output = client.generate(input, max_new_tokens=slider).generated_text\n",
    "    output = [\n",
    "        conversation.get(\"utterances\")\n",
    "        for conversation in conversations_generator\n",
    "    ]\n",
    "    return output\n",
    "\n",
    "demo = gr.Interface(fn=topic, \n",
    "                    inputs=[gr.Textbox(label=\"Prompt\"),\n",
    "                            gr.Slider(label=\"Max new tokens\", value=20, maximum=1024, minimum=1)],\n",
    "                    outputs=[gr.Textbox(label=\"Completion\")])\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## PyAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyai = \"\"\"\n",
    "You are an expert Python developer with years of experience writing Python code and teaching Python to other programmers. \n",
    "You have vast experience mentoring developers.\n",
    "You write idiomatic Python code and try to find the most Pythonic way to solve problems.\n",
    "I want you to be my mentor while I write Python code. \n",
    "I'm an intermediate Python developer.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=f\"{pyai} Type 'okay' if you understood.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = \"\"\"\n",
    "I'm working on a project to generate text datasets using LLMs. \n",
    "The main use case is to produce human-like conversations using AI generation.\n",
    "One way to do this is to have two AI agents having a conversation.\n",
    "Let's brainstorm approaches on how to do this. \n",
    "Do you have any ideas?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=f\"{inp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = \"\"\"\n",
    "Let's start with a basic approach.\n",
    "It seems as if the 'dialogue rollouts' technique might be easier to implement, do you agree?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=f\"{inp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = \"\"\"\n",
    "You're going to help me write Python code to implement and produce interesting conversations between AI agents.\n",
    "I'm familiar with LangChain but I'm open to using other Python libraries, if you feel there's a better approach.\n",
    "Help me get started.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=f\"{inp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Work In Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "chat_model = ChatOpenAI(model='gpt-3.5-turbo')\n",
    "memory = ConversationBufferMemory(size=5)\n",
    "chain = ConversationChain(llm=chat_model, memory=memory, verbose=True)\n",
    "\n",
    "# Define personalities\n",
    "personalities = {\n",
    "    \"OM\": \"You are a 60-year-old retired schoolteacher with a hearty laugh and love for life. Known for his long-winded stories, he's endearing, kind-hearted, and a little forgetful at times. Often seen with a book in his hand or playing chess in the park, he has a youthful spirit and is always ready for an adventure. Your name is Oliver 'Ollie' Martinez.\",\n",
    "    \"GK\": \"You are an ambitious and meticulous 30-year-old tech entrepreneur. Known for her innovative ideas and relentless work ethic, she's assertive, intelligent, and a little bit intimidating. Outside of work, she's a passionate foodie who loves trying out new recipes and exploring local eateries. Your name is Grace Kim.\",\n",
    "    \"ST\": \"You are a free-spirited 25-year-old artist and environmental activist. Always carrying her sketchbook, she's spontaneous, compassionate, and a tad unconventional. She's the one friends call at 2 AM for deep conversations about life, philosophy, and how to save the world. Your name is Samara 'Sam' Thompson.\",\n",
    "    \"ER\": \"You are a 35-year-old quiet and thoughtful architect with a dry sense of humor. He is analytical, introverted, and slightly reserved. He finds comfort in solitude and loves classical music. Though he may seem aloof, he's a loyal friend who listens more than he speaks. Your name is Ethan Reid.\",\n",
    "    \"LA\": \"You are a chirpy and friendly 22-year-old aspiring actress working as a waitress. She is dramatic, vibrant, and full of energy. Despite the struggles of her profession, she's always positive, seeing every hurdle as an opportunity to grow. She loves the spotlight, performing arts, and meeting new people. Your name is Lily Anderson.\"\n",
    "}\n",
    "\n",
    "# Randomly select two personalities\n",
    "def select_personalities(personalities):\n",
    "    selected_keys = random.sample(list(personalities), 2)\n",
    "    return personalities[selected_keys[0]], personalities[selected_keys[1]]\n",
    "\n",
    "# Generate a random topic using the OpenAI model\n",
    "def generate_topic():\n",
    "    topic_prompt = \"Generate a common conversation topic between two people.\"\n",
    "    topic = chain.predict(input=topic_prompt)\n",
    "    return topic\n",
    "\n",
    "# Build conversation starter\n",
    "def conversation_starter(personality1, personality2, topic):\n",
    "    return f\"{personality1[:2]} starts {topic}\\n{personality1}\\n{personality2[:2]} responds\\n{personality2}\"\n",
    "\n",
    "# Select personalities and generate a topic\n",
    "personality1, personality2 = select_personalities(personalities)\n",
    "topic = generate_topic()\n",
    "starter = conversation_starter(personality1, personality2, topic)\n",
    "\n",
    "print(starter)\n",
    "\n",
    "# Create prompts based on personalities and starter\n",
    "prompts = [f\"{personality1[:2]}: {starter}\", f\"{personality2[:2]}: {starter}\"]\n",
    "\n",
    "# Simulate conversation\n",
    "for prompt in prompts:\n",
    "    response = chain.predict(input=prompt)\n",
    "    print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import glob\n",
    "\n",
    "def concat_jsons(directory):\n",
    "    \"\"\"\n",
    "    Load and concatenate JSON files from a specified directory into a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    directory (str): The directory containing the JSON files to load.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: The concatenated DataFrame.\n",
    "    \"\"\"\n",
    "    # Define a list to store the data\n",
    "    data_frames = []\n",
    "\n",
    "    # Use glob to match the pattern '*.json' in the specified directory\n",
    "    json_files = glob.glob(os.path.join(directory, '*.json'))\n",
    "\n",
    "    for file in json_files:\n",
    "        with open(file, 'r') as f:\n",
    "            # Load the JSON file into a dictionary\n",
    "            data = json.load(f)\n",
    "\n",
    "            # Normalize semi-structured JSON data into a flat table.\n",
    "            temp_df = pd.json_normalize(data, 'utterances', ['sample_id', 'length', 'temperature', 'initial_utterance', 'n', 'agent1', 'agent2'], \n",
    "                                        record_prefix='utterance_')\n",
    "\n",
    "            # Append the DataFrame to the list\n",
    "            data_frames.append(temp_df)\n",
    "\n",
    "    # Concatenate all the DataFrames in the list\n",
    "    df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "    return df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
